* 收获
  - pandas的to_datetime()可以直接将日期字符串转为对象
    如pd.to_datetime(df['Dates'])
  - 读取文件时, 可以直接将日期一列解析为Datetime类型
    如pd.read_csv('train.csv', parse_dates=['Dates'])
  - 想办法提取字符串里的数字特征
  - 想办法提取字符串里有含义的特征
  - 不要轻易用dummies变量, 会增加维度, 有时可以用dict(str->int)代替
  - 模型的verbose参数可以显示训练进度
* 感想
  - 太TMD震撼了, 随机森林里改了个默认参数min_samples_split(从默认值2改为1000), 效果却出人意料的好(精度提高7个点, 名次提升780名, 一举杀入前20%), 本来以为改这个参数只是会节省内存的, 对于效果的提升完全是没有料到的.
  还没有上特征工程的东西. 看来还是要深入理解模型, 才能调的一手好参
  - SVM做多分类简直要死人啊, 不是一般的慢(到底是多分类的原因还是样本数过多的原因? 分类数40, 样本数87w, 特征维数也就不到50)
  - 随机森林的n_jobs参数是多线程跑的意思, 但是有个问题, 会复制数据, 不是数据共享, 所以会很耗内存. 不像作者声明的在高版本中解决了, 费内存的问题仍然存在
  - 经验对调参的作用, 比方说根据数据规模大小选择不同的参数, 比方说GBM, 如果数据量小, 树的数目过大的话会过拟合
